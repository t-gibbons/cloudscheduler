#!/usr/bin/python3
import os
import logging
import cloudscheduler.jobmanager
import cloudscheduler.cloudmanager
import cloudscheduler.config as csconfig

from lib.schema import view_groups_of_idle_jobs
from lib.schema import view_resources_matching_idle_jobs

from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.ext.automap import automap_base


CLOUDRESOURCES = {}

logging.basicConfig(level=logging.DEBUG,
                    format="%(asctime)s:%(levelname)s:%(message)s")


def main():
    """
    main function.
    """
    log = logging.getLogger(__name__)
    while(True):
        # basic scheduling: fifo w/ condor_prioity

        Base0 = automap_base()
        engine0 = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
        Base0.prepare(engine0, reflect=True)
        CSGroups = Base0.classes.csv2_groups
        session0 = Session(engine0)
        # Get all the current csv2_groups
        csv2groups = session0.query(CSGroups)
        #logging.debug(type(csv2groups))
        #log.debug(type(csv2groups[0]),csv2groups[0])
        for csgroup in csv2groups:
            log.debug(csgroup.group_name)

            # Setup the resources for group and sort out their group and cloud specific yamls
            Base = automap_base()
            engine = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
            Base.prepare(engine, reflect=True)
            session = Session(engine)

            Resources = Base.classes.csv2_group_resources
            group_resources = session.query(Resources).filter(Resources.group_name == csgroup.group_name)
            Group_Yaml = Base.classes.csv2_group_yaml
            group_yamls = session.query(Group_Yaml).filter(Group_Yaml.group_name == csgroup.group_name)
            group_yaml_list = []
            for yam in group_yamls:
                group_yaml_list.append((yam.yaml_name, yam.yaml, yam.mime_type))
            cm_group = cloudscheduler.cloudmanager.CloudManager(name=csgroup.group_name, group_resources=group_resources, group_yamls=group_yaml_list)
            cm_group.setup()
            # At this point I should have a valid set of all the group and cloud specific yaml to use
            # it will still need to be combined with the job yaml - done now in the basecloud prepare_userdata function


            # Booting up new VMs to fill in any free space on available clouds related to idle queued jobs
            # Get the idle jobs for the current group
            idle_jobs_for_group = session.query(view_groups_of_idle_jobs).filter(
                view_groups_of_idle_jobs.c.group_name == csgroup.group_name).order_by(
                view_groups_of_idle_jobs.c.job_priority)
            log.debug('got idle jobs')
            for idle_job in idle_jobs_for_group:

                log.debug(idle_job.flavors) # flavors is generated line based on which flavor is the best fit and which clouds have available resources
                    # the format is "Group:Cloud:Flavor, Group:Cloud:Flavor" will need to split and use to filter in resources_matching
                job_count = idle_job.count # number of jobs with identical request
                log.debug(job_count)
                flavor_list = [x.strip() for x in idle_job.flavors.split(',')]
                log.debug(flavor_list)
                target_cloud_list = [x.strip() for x in idle_job.target_clouds.split(',')]
                log.debug(target_cloud_list)
                for tri in flavor_list:
                    (group, cloud, flavor) = tri.split(':')
                    log.debug(tri)
                    log.debug("%s, %s, %s", group, cloud, flavor)

                    clouds_matching = session.query(view_resources_matching_idle_jobs).filter(
                        view_resources_matching_idle_jobs.c.flavor == tri,
                        view_resources_matching_idle_jobs.c.cloud_name.in_(target_cloud_list)) # awkward syntax but works.
                    for cloud_match in clouds_matching:
                        #log.debug(cloud_match.flavor_id) # id of flavor to avoid naming conflicts (may not need but doesn't hurt)
                        #log.debug(cloud_match.flavor_name) # alternative to the id
                        #log.debug(cloud_match.cloud_name) # can use this if i've constructed the resources previously.
                        #log.debug(cloud_match.flavor_slots)  # how many of that flavor can be booted
                        # how many VMs should I try to boot? lets just go for max we can for now until we add config for limits
                        num_vms_to_boot = job_count if job_count <= cloud_match.flavor_slots else cloud_match.flavor_slots
                        template_dict = {'cs_user': idle_job.user,
                                         'cs_group_name': csgroup.group_name,
                                         'cs_condor_host': csgroup.condor_central_manager}
                        cm_group.clouds[cloud_match.cloud_name].vm_create(group_yaml_list=cm_group.group_yamls,
                                                                          num=num_vms_to_boot,
                                                                          flavor=cloud_match.flavor_name,
                                                                          job=idle_job,
                                                                          template_dict=template_dict)
                        job_count -= num_vms_to_boot
                        log.debug('done booting on cloud')


        break # will need to take this out and put in an actual stopping condition.

    import time
    time.sleep(10)

    # Remove all the VMs for the moment
    for user in CLOUDRESOURCES:
        for cloud in CLOUDRESOURCES[user].clouds:
            for vm in list(CLOUDRESOURCES[user].clouds[cloud].vms.keys()):
                CLOUDRESOURCES[user].clouds[cloud].vm_destroy(CLOUDRESOURCES[user].clouds[cloud].vms[vm])
# maintain a dict of cloudmanager objects
# initially load up the default one
# when new user detected check for a cloud resource file and load / add to dict key user name

# should re-adapt this to deal with adding group from DB and splitting code into functions instead of all inline
def add_user_cloud(user, user_resource_file=None):
    """

    :param user:
    :param user_resource_file:
    """
    if not user_resource_file:
        homedir = os.path.expanduser(''.join['~', user])
        user_resource_file = ''.join([homedir, '/.cloudscheduler/cloudresources.yaml'])
    cmuser = cloudscheduler.cloudmanager.CloudManager(name=user, resource_file=user_resource_file)
    cmuser.setup()
    CLOUDRESOURCES[cmuser.name] = cmuser


main()
